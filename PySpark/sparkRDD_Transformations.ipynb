{"cells":[{"cell_type":"code","source":["# Return a new distributed dataset formed by passing each element of the source through a function func.\ndata = [1,2,3,4,5]\nsource_RDD=sc.parallelize(data,4)\nresult_RDD = source_RDD.map(lambda x:x**2)\nprint('Source RDD=',source_RDD.collect())\nprint('Result RDD after map = ',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"map(func)","showTitle":true,"inputWidgets":{},"nuid":"f6f2b214-62d7-466f-acec-118eb50ca02f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD= [1, 2, 3, 4, 5]\nResult RDD after map =  [1, 4, 9, 16, 25]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD= [1, 2, 3, 4, 5]\nResult RDD after map =  [1, 4, 9, 16, 25]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Return a new dataset formed by selecting those elements of the source on which func returns true.\ndata = [1,2,3,4,5]\nsource_RDD=sc.parallelize(data,4)\nresult_RDD = source_RDD.filter(lambda x:x%2==0) # lambda function returns true when the element is even\nprint('Source RDD=',source_RDD.collect())\nprint('Result RDD after filter = ',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"filter(func)","showTitle":true,"inputWidgets":{},"nuid":"7455910f-ada5-4d11-b205-96078ddef353"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD= [1, 2, 3, 4, 5]\nResult RDD after filter =  [2, 4]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD= [1, 2, 3, 4, 5]\nResult RDD after filter =  [2, 4]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Similar to map, but each input item can be mapped to 0 or more output items (so func should return a Seq rather than a single item).\ndata = [1,2,3,4,5]\nsource_RDD=sc.parallelize(data,4)\nresult_RDD1 = source_RDD.flatMap(lambda x:(x,x))\nresult_RDD2 = source_RDD.flatMap(lambda x:[(x,x**2)])\nresult_RDD3 = source_RDD.flatMap(lambda x:range(1,x))\nprint('Source RDD=',source_RDD.collect())\nprint('Result RDD1 after flatMap = ',result_RDD1.collect())\nprint('Result RDD2 after flatMap = ',result_RDD2.collect())\nprint('Result RDD3 after flatMap = ',result_RDD3.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"flatMap(func)","showTitle":true,"inputWidgets":{},"nuid":"8b24d201-eec3-4b84-8afd-d2bc4323d713"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD= [1, 2, 3, 4, 5]\nResult RDD1 after flatMap =  [1, 1, 2, 2, 3, 3, 4, 4, 5, 5]\nResult RDD2 after flatMap =  [(1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\nResult RDD3 after flatMap =  [1, 1, 2, 1, 2, 3, 1, 2, 3, 4]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD= [1, 2, 3, 4, 5]\nResult RDD1 after flatMap =  [1, 1, 2, 2, 3, 3, 4, 4, 5, 5]\nResult RDD2 after flatMap =  [(1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\nResult RDD3 after flatMap =  [1, 1, 2, 1, 2, 3, 1, 2, 3, 4]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Similar to map, but runs separately on each partition (block) of the RDD, so func must be of type Iterator<T> => Iterator<U> when running on an RDD of type T.\n\ndef process_partition(partitions):\n  yield sum(partitions)\n  \ndata = [1,2,3,3,2,5,2,4,3]\nsource_RDD = sc.parallelize(data,3)\nprint('Source RDD=',source_RDD.collect())\nprint('Source RDD at partition level=',source_RDD.glom().collect())\nresult_RDD = source_RDD.mapPartitions(process_partition)\nprint('Resultant RDD after mapPartitions=',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"mapPartitions(func)","showTitle":true,"inputWidgets":{},"nuid":"289a698a-060c-41fe-99d1-d8c8d10054a7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD= [1, 2, 3, 3, 2, 5, 2, 4, 3]\nSource RDD at partition level= [[1, 2, 3], [3, 2, 5], [2, 4, 3]]\nResultant RDD after mapPartitions= [6, 10, 9]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD= [1, 2, 3, 3, 2, 5, 2, 4, 3]\nSource RDD at partition level= [[1, 2, 3], [3, 2, 5], [2, 4, 3]]\nResultant RDD after mapPartitions= [6, 10, 9]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Similar to mapPartitions, but also provides func with an integer value representing the index of the partition, so func must be of type (Int, Iterator<T>) => Iterator<U> when running on an RDD of type T.\ndef process_partition(index,iterator):\n  yield (index,sum(iterator))\n  \ndata = [1,2,3,3,2,5,2,4,3]\nsource_RDD = sc.parallelize(data,3)\nprint('Source RDD=',source_RDD.collect())\nprint('Source RDD at partition level=',source_RDD.glom().collect())\nresult_RDD = source_RDD.mapPartitionsWithIndex(process_partition)\nprint('Resultant RDD after mapPartitionsWithIndex=',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"mapPartitionsWithIndex(func)","showTitle":true,"inputWidgets":{},"nuid":"dfb47985-d916-4483-a2a3-714536a99206"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD= [1, 2, 3, 3, 2, 5, 2, 4, 3]\nSource RDD at partition level= [[1, 2, 3], [3, 2, 5], [2, 4, 3]]\nResultant RDD after mapPartitionsWithIndex= [(0, 6), (1, 10), (2, 9)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD= [1, 2, 3, 3, 2, 5, 2, 4, 3]\nSource RDD at partition level= [[1, 2, 3], [3, 2, 5], [2, 4, 3]]\nResultant RDD after mapPartitionsWithIndex= [(0, 6), (1, 10), (2, 9)]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Sample a fraction fraction of the data, with or without replacement, using a given random number generator seed.\ndata = range(1,101)\nsource_RDD=sc.parallelize(data)\nresult_RDD = source_RDD.sample(False,0.1,1)\nprint('Source RDD=',source_RDD.collect())\nprint('Result RDD after sample = ',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"sample(withReplacement, fraction, seed)","showTitle":true,"inputWidgets":{},"nuid":"a0637012-3afe-48bb-ab9a-0b8888bc908d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD= [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\nResult RDD after sample =  [12, 37, 61, 66, 73, 76, 80, 85, 87]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD= [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\nResult RDD after sample =  [12, 37, 61, 66, 73, 76, 80, 85, 87]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Return a new dataset that contains the union of the elements in the source dataset and the argument.\ndata=[1,2,3]\ndata2 = [2,4,5]\nsource_RDD = sc.parallelize(data)\nargument_RDD = sc.parallelize(data2)\nresult_RDD = source_RDD.union(argument_RDD)\nprint('Source RDD=',source_RDD.collect())\nprint('Another RDD=',argument_RDD.collect())\nprint('Result RDD after union = ',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"union(otherDataset)","showTitle":true,"inputWidgets":{},"nuid":"06adedf2-9409-4fee-9d96-b8799b0cbd09"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD= [1, 2, 3]\nAnother RDD= [2, 4, 5]\nResult RDD after union =  [1, 2, 3, 2, 4, 5]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD= [1, 2, 3]\nAnother RDD= [2, 4, 5]\nResult RDD after union =  [1, 2, 3, 2, 4, 5]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Return a new RDD that contains the intersection of elements in the source dataset and the argument.\ndata=[1,2,3]\ndata2 = [2,4,5]\nsource_RDD = sc.parallelize(data)\nargument_RDD = sc.parallelize(data2)\nresult_RDD = source_RDD.intersection(argument_RDD)\nprint('Source RDD=',source_RDD.collect())\nprint('Another RDD=',argument_RDD.collect())\nprint('Result RDD after intersection = ',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"intersection(otherDataset)","showTitle":true,"inputWidgets":{},"nuid":"cc2ce91d-31b4-457f-a32b-ef503eb323d8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD= [1, 2, 3]\nAnother RDD= [2, 4, 5]\nResult RDD after intersection =  [2]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD= [1, 2, 3]\nAnother RDD= [2, 4, 5]\nResult RDD after intersection =  [2]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Return a new dataset that contains the distinct elements of the source dataset.\ndata=[1,2,2,3,5,5]\nsource_RDD = sc.parallelize(data)\nresult_RDD = source_RDD.distinct(2)\nprint('Source RDD=',source_RDD.collect())\nprint('Result RDD after distinct = ',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"distinct([numPartitions]))","showTitle":true,"inputWidgets":{},"nuid":"d2f56eac-9f65-48fa-b4e5-43d7b8e5aeb7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD= [1, 2, 2, 3, 5, 5]\nResult RDD after distinct =  [2, 1, 3, 5]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD= [1, 2, 2, 3, 5, 5]\nResult RDD after distinct =  [2, 1, 3, 5]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# When called on a dataset of (K, V) pairs, returns a dataset of (K, Iterable<V>) pairs.\n# Note: If you are grouping in order to perform an aggregation (such as a sum or average) over each key, using reduceByKey or aggregateByKey will yield much better performance.\n# Note: By default, the level of parallelism in the output depends on the number of partitions of the parent RDD. You can pass an optional numPartitions argument to set a different number of tasks.\ndata=[(1,'A'),(2,'B'),(3,'C'),(4,'D'),(1,'D'),(4,'H'),(1,'Z'),(3,'O'),(3,'P')]\nsource_RDD = sc.parallelize(data)\nresult_RDD = source_RDD.groupByKey(2)\nprint('Source RDD=',source_RDD.collect())\nprint('Result RDD after groupByKey = ',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"groupByKey([numPartitions])","showTitle":true,"inputWidgets":{},"nuid":"4ea626ab-5c2e-4fab-ab1e-6de6c760d246"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD= [(1, &#39;A&#39;), (2, &#39;B&#39;), (3, &#39;C&#39;), (4, &#39;D&#39;), (1, &#39;D&#39;), (4, &#39;H&#39;), (1, &#39;Z&#39;), (3, &#39;O&#39;), (3, &#39;P&#39;)]\nResult RDD after groupByKey =  [(2, &lt;pyspark.resultiterable.ResultIterable object at 0x7f74718a7cd0&gt;), (4, &lt;pyspark.resultiterable.ResultIterable object at 0x7f74716be5e0&gt;), (1, &lt;pyspark.resultiterable.ResultIterable object at 0x7f74716be910&gt;), (3, &lt;pyspark.resultiterable.ResultIterable object at 0x7f74716be670&gt;)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD= [(1, &#39;A&#39;), (2, &#39;B&#39;), (3, &#39;C&#39;), (4, &#39;D&#39;), (1, &#39;D&#39;), (4, &#39;H&#39;), (1, &#39;Z&#39;), (3, &#39;O&#39;), (3, &#39;P&#39;)]\nResult RDD after groupByKey =  [(2, &lt;pyspark.resultiterable.ResultIterable object at 0x7f74718a7cd0&gt;), (4, &lt;pyspark.resultiterable.ResultIterable object at 0x7f74716be5e0&gt;), (1, &lt;pyspark.resultiterable.ResultIterable object at 0x7f74716be910&gt;), (3, &lt;pyspark.resultiterable.ResultIterable object at 0x7f74716be670&gt;)]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# To see the Iterable in the above cell\n# We can turn the results of groupByKey into a list by calling list() \nresult_RDD=source_RDD.groupByKey().map(lambda x : (x[0], list(x[1]))).collect()\nprint('Result RDD after groupByKey with map = ',result_RDD)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4394906-8493-43ec-8988-88a2386696d4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Result RDD after groupByKey with map =  [(1, [&#39;A&#39;, &#39;D&#39;, &#39;Z&#39;]), (2, [&#39;B&#39;]), (3, [&#39;C&#39;, &#39;O&#39;, &#39;P&#39;]), (4, [&#39;D&#39;, &#39;H&#39;])]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Result RDD after groupByKey with map =  [(1, [&#39;A&#39;, &#39;D&#39;, &#39;Z&#39;]), (2, [&#39;B&#39;]), (3, [&#39;C&#39;, &#39;O&#39;, &#39;P&#39;]), (4, [&#39;D&#39;, &#39;H&#39;])]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# When called on a dataset of (K, V) pairs, returns a dataset of (K, V) pairs where the values for each key are aggregated using the given reduce function func, which must be of type (V,V) => V. Like in groupByKey, the number of reduce tasks is configurable through an optional second argument.\ndata=[(1,'A'),(2,'B'),(3,'C'),(4,'D'),(1,'D'),(4,'H'),(1,'Z'),(3,'O'),(3,'P')]\nsource_RDD = sc.parallelize(data)\nresult_RDD = source_RDD.reduceByKey(lambda a,b:a+b) # Using lambda function to concatenate the string based on keys\nprint('Source RDD=',source_RDD.collect())\nprint('Result RDD after reduceByKey = ',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"reduceByKey(func, [numPartitions])","showTitle":true,"inputWidgets":{},"nuid":"0ffe115b-8fe0-4f3c-beac-690c080e3ff9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD= [(1, &#39;A&#39;), (2, &#39;B&#39;), (3, &#39;C&#39;), (4, &#39;D&#39;), (1, &#39;D&#39;), (4, &#39;H&#39;), (1, &#39;Z&#39;), (3, &#39;O&#39;), (3, &#39;P&#39;)]\nResult RDD after reduceByKey =  [(1, &#39;ADZ&#39;), (2, &#39;B&#39;), (3, &#39;COP&#39;), (4, &#39;DH&#39;)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD= [(1, &#39;A&#39;), (2, &#39;B&#39;), (3, &#39;C&#39;), (4, &#39;D&#39;), (1, &#39;D&#39;), (4, &#39;H&#39;), (1, &#39;Z&#39;), (3, &#39;O&#39;), (3, &#39;P&#39;)]\nResult RDD after reduceByKey =  [(1, &#39;ADZ&#39;), (2, &#39;B&#39;), (3, &#39;COP&#39;), (4, &#39;DH&#39;)]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# When called on a dataset of (K, V) pairs, returns a dataset of (K, U) pairs where the values for each key are aggregated using the given combine functions and a neutral \"zero\" value. Allows an aggregated value type that is different than the input value type, while avoiding unnecessary allocations. Like in groupByKey, the number of reduce tasks is configurable through an optional second argument.\ndata=[('A',1),('B',10),('C',3),('A',4),('C',3),('C',5)]\nsource_RDD = sc.parallelize(data)\nseqFunc = (lambda x,y: (x[0]+y,x[1]+1))\ncombFunc = (lambda rdd1,rdd2: (rdd1[0]+rdd2[0],rdd1[1]+rdd2[1]))\nresult_RDD = source_RDD.aggregateByKey((0, 0),seqFunc,combFunc) \nprint('Source RDD=',source_RDD.collect())\nprint('Source RDD=',source_RDD.glom().collect())\nprint('Result RDD after aggregateByKey = ',result_RDD.collect()) # returns the sum of values of each key and the number of occurance of each key"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"aggregateByKey(zeroValue, seqFunc, combFunc)","showTitle":true,"inputWidgets":{},"nuid":"57cc92fb-48f4-4987-8d90-3be996228c3c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD= [(&#39;A&#39;, 1), (&#39;B&#39;, 10), (&#39;C&#39;, 3), (&#39;A&#39;, 4), (&#39;C&#39;, 3), (&#39;C&#39;, 5)]\nSource RDD= [[], [(&#39;A&#39;, 1)], [(&#39;B&#39;, 10)], [(&#39;C&#39;, 3)], [], [(&#39;A&#39;, 4)], [(&#39;C&#39;, 3)], [(&#39;C&#39;, 5)]]\nResult RDD after aggregateByKey =  [(&#39;B&#39;, (10, 1)), (&#39;C&#39;, (11, 3)), (&#39;A&#39;, (5, 2))]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD= [(&#39;A&#39;, 1), (&#39;B&#39;, 10), (&#39;C&#39;, 3), (&#39;A&#39;, 4), (&#39;C&#39;, 3), (&#39;C&#39;, 5)]\nSource RDD= [[], [(&#39;A&#39;, 1)], [(&#39;B&#39;, 10)], [(&#39;C&#39;, 3)], [], [(&#39;A&#39;, 4)], [(&#39;C&#39;, 3)], [(&#39;C&#39;, 5)]]\nResult RDD after aggregateByKey =  [(&#39;B&#39;, (10, 1)), (&#39;C&#39;, (11, 3)), (&#39;A&#39;, (5, 2))]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# When called on a dataset of (K, V) pairs where K implements Ordered, returns a dataset of (K, V) pairs sorted by keys in ascending or descending order, as specified in the boolean ascending argument.\ndata=[(1,'A'),(2,'B'),(3,'C'),(4,'D'),(1,'D'),(4,'H'),(1,'Z'),(3,'O'),(3,'P')]\nsource_RDD = sc.parallelize(data)\nresult_RDD = source_RDD.sortByKey()\nprint('Source RDD=',source_RDD.collect())\nprint('Result RDD after sortByKey = ',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"sortByKey([ascending], [numPartitions])","showTitle":true,"inputWidgets":{},"nuid":"3484ea1a-d66d-448b-9984-3b1d7c142b89"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD= [(1, &#39;A&#39;), (2, &#39;B&#39;), (3, &#39;C&#39;), (4, &#39;D&#39;), (1, &#39;D&#39;), (4, &#39;H&#39;), (1, &#39;Z&#39;), (3, &#39;O&#39;), (3, &#39;P&#39;)]\nResult RDD after sortByKey =  [(1, &#39;A&#39;), (1, &#39;D&#39;), (1, &#39;Z&#39;), (2, &#39;B&#39;), (3, &#39;C&#39;), (3, &#39;O&#39;), (3, &#39;P&#39;), (4, &#39;D&#39;), (4, &#39;H&#39;)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD= [(1, &#39;A&#39;), (2, &#39;B&#39;), (3, &#39;C&#39;), (4, &#39;D&#39;), (1, &#39;D&#39;), (4, &#39;H&#39;), (1, &#39;Z&#39;), (3, &#39;O&#39;), (3, &#39;P&#39;)]\nResult RDD after sortByKey =  [(1, &#39;A&#39;), (1, &#39;D&#39;), (1, &#39;Z&#39;), (2, &#39;B&#39;), (3, &#39;C&#39;), (3, &#39;O&#39;), (3, &#39;P&#39;), (4, &#39;D&#39;), (4, &#39;H&#39;)]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# When called on datasets of type (K, V) and (K, W), returns a dataset of (K, (V, W)) pairs with all pairs of elements for each key. Outer joins are supported through leftOuterJoin, rightOuterJoin, and fullOuterJoin.\ndata1=[(1,'A'),(2,'B'),(3,'C')]\ndata2=[(1,'F'),(3,'L'),(4,'M')]\nsource_RDD1 = sc.parallelize(data1)\nsource_RDD2 = sc.parallelize(data2)\nresult_RDD = source_RDD1.join(source_RDD2)\nprint('Source RDD 1=',source_RDD1.collect())\nprint('Source RDD 2=',source_RDD2.collect())\nprint('Result RDD after join = ',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"join(otherDataset, [numPartitions])","showTitle":true,"inputWidgets":{},"nuid":"6eed7be6-39ef-48d5-be97-be58f2f18250"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD 1= [(1, &#39;A&#39;), (2, &#39;B&#39;), (3, &#39;C&#39;)]\nSource RDD 2= [(1, &#39;F&#39;), (3, &#39;L&#39;), (4, &#39;M&#39;)]\nResult RDD after join =  [(1, (&#39;A&#39;, &#39;F&#39;)), (3, (&#39;C&#39;, &#39;L&#39;))]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD 1= [(1, &#39;A&#39;), (2, &#39;B&#39;), (3, &#39;C&#39;)]\nSource RDD 2= [(1, &#39;F&#39;), (3, &#39;L&#39;), (4, &#39;M&#39;)]\nResult RDD after join =  [(1, (&#39;A&#39;, &#39;F&#39;)), (3, (&#39;C&#39;, &#39;L&#39;))]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# When called on datasets of type (K, V) and (K, W), returns a dataset of (K, (Iterable<V>, Iterable<W>)) tuples. This operation is also called groupWith.\ndata1=[(1,'A'),(2,'B'),(3,'C')]\ndata2=[(1,'F'),(3,'L'),(4,'M')]\nsource_RDD1 = sc.parallelize(data1)\nsource_RDD2 = sc.parallelize(data2)\nresult_RDD = source_RDD1.cogroup(source_RDD2)\nprint('Source RDD 1=',source_RDD1.collect())\nprint('Source RDD 2=',source_RDD2.collect())\nprint('Result RDD after cogroup = ',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"cogroup(otherDataset, [numPartitions])","showTitle":true,"inputWidgets":{},"nuid":"d7b7934e-85f7-4a28-bb75-889abcb3ede4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD 1= [(1, &#39;A&#39;), (2, &#39;B&#39;), (3, &#39;C&#39;)]\nSource RDD 2= [(1, &#39;F&#39;), (3, &#39;L&#39;), (4, &#39;M&#39;)]\nResult RDD after cogroup =  [(1, (&lt;pyspark.resultiterable.ResultIterable object at 0x7f7471723fd0&gt;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f74716be5b0&gt;)), (2, (&lt;pyspark.resultiterable.ResultIterable object at 0x7f74716beb80&gt;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f74716bedc0&gt;)), (3, (&lt;pyspark.resultiterable.ResultIterable object at 0x7f74716be3a0&gt;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f7471709c40&gt;)), (4, (&lt;pyspark.resultiterable.ResultIterable object at 0x7f7471709cd0&gt;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f7471709e80&gt;))]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD 1= [(1, &#39;A&#39;), (2, &#39;B&#39;), (3, &#39;C&#39;)]\nSource RDD 2= [(1, &#39;F&#39;), (3, &#39;L&#39;), (4, &#39;M&#39;)]\nResult RDD after cogroup =  [(1, (&lt;pyspark.resultiterable.ResultIterable object at 0x7f7471723fd0&gt;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f74716be5b0&gt;)), (2, (&lt;pyspark.resultiterable.ResultIterable object at 0x7f74716beb80&gt;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f74716bedc0&gt;)), (3, (&lt;pyspark.resultiterable.ResultIterable object at 0x7f74716be3a0&gt;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f7471709c40&gt;)), (4, (&lt;pyspark.resultiterable.ResultIterable object at 0x7f7471709cd0&gt;, &lt;pyspark.resultiterable.ResultIterable object at 0x7f7471709e80&gt;))]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# When called on datasets of types T and U, returns a dataset of (T, U) pairs (all pairs of elements).\nsource_RDD1 = sc.parallelize([0,1])\nsource_RDD2 = sc.parallelize([3,4])\nresult_RDD = source_RDD1.cartesian(source_RDD2)\nprint('Source RDD 1=',source_RDD1.collect())\nprint('Source RDD 2=',source_RDD2.collect())\nprint('Result RDD after cogroup = ',result_RDD.collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"cartesian(otherDataset)","showTitle":true,"inputWidgets":{},"nuid":"c23d60ed-b601-46f6-9fe5-1ae67177e9fd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Source RDD 1= [0, 1]\nSource RDD 2= [3, 4]\nResult RDD after cogroup =  [(0, 3), (0, 4), (1, 3), (1, 4)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Source RDD 1= [0, 1]\nSource RDD 2= [3, 4]\nResult RDD after cogroup =  [(0, 3), (0, 4), (1, 3), (1, 4)]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Pipe each partition of the RDD through a shell command, e.g. a Perl or bash script. RDD elements are written to the process's stdin and lines output to its stdout are returned as an RDD of strings.\nsc.parallelize([1, 2, 3, 4]).pipe('cat').collect()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"pipe(command, [envVars])","showTitle":true,"inputWidgets":{},"nuid":"16d0f9c8-3811-49ed-98f3-44ec204eae54"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[245]: [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[245]: [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Decrease the number of partitions in the RDD to numPartitions. Useful for running operations more efficiently after filtering down a large dataset.\ndata = [1,2,3,4]\nsource_RDD = sc.parallelize(data,4)\nresult_RDD = source_RDD.coalesce(2)\nprint(\"No. of Partitions before coalesce: \" ,source_RDD.getNumPartitions())\nprint(\"Partitions before coalesce: \" ,source_RDD.glom().collect())\nprint(\"No. of Partitions after coalesce: \" ,result_RDD.getNumPartitions())\nprint(\"Partitions after coalesce: \" ,result_RDD.glom().collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"coalesce(numPartitions)","showTitle":true,"inputWidgets":{},"nuid":"4041e4f0-60a0-4d37-a431-1d67f00b4f59"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">No. of Partitions before coalesce:  4\nPartitions before coalesce:  [[1], [2], [3], [4]]\nNo. of Partitions after coalesce:  2\nPartitions after coalesce:  [[1, 2], [3, 4]]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">No. of Partitions before coalesce:  4\nPartitions before coalesce:  [[1], [2], [3], [4]]\nNo. of Partitions after coalesce:  2\nPartitions after coalesce:  [[1, 2], [3, 4]]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Reshuffle the data in the RDD randomly to create either more or fewer partitions and balance it across them. This always shuffles all data over the network.\ndata = [1,2,3,4]\nsource_RDD = sc.parallelize(data,4)\nresult_RDD = source_RDD.repartition(2)\nprint(\"No. of Partitions before repartition: \" ,source_RDD.getNumPartitions())\nprint(\"Partitions before repartition: \" ,source_RDD.glom().collect())\nprint(\"No. of Partitions after repartition: \" ,result_RDD.getNumPartitions())\nprint(\"Partitions after repartition: \" ,result_RDD.glom().collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"repartition(numPartitions)","showTitle":true,"inputWidgets":{},"nuid":"fbed5d23-3f38-4d2a-8dd1-2d441c910026"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">No. of Partitions before repartition:  4\nPartitions before repartition:  [[1], [2], [3], [4]]\nNo. of Partitions after repartition:  2\nPartitions after repartition:  [[1, 3, 4], [2]]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">No. of Partitions before repartition:  4\nPartitions before repartition:  [[1], [2], [3], [4]]\nNo. of Partitions after repartition:  2\nPartitions after repartition:  [[1, 3, 4], [2]]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Repartition the RDD according to the given partitioner and, within each resulting partition, sort records by their keys. This is more efficient than calling repartition and then sorting within each partition because it can push the sorting down into the shuffle machinery.\nsource_RDD  = sc.parallelize([[\"a\",1], [\"b\",2], [\"c\",3], [\"d\",3]])\nresult_RDD = source_RDD.repartitionAndSortWithinPartitions(2) \nprint(\"RDD :\", source_RDD.collect())\nprint(\"RDD after repartitionAndSortWithinPartitions:\", result_RDD.glom().collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"repartitionAndSortWithinPartitions(partitioner)","showTitle":true,"inputWidgets":{},"nuid":"b7c93191-c508-4afe-8c71-3ea6bdfb76ba"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">RDD : [[&#39;a&#39;, 1], [&#39;b&#39;, 2], [&#39;c&#39;, 3], [&#39;d&#39;, 3]]\nRDD after repartitionAndSortWithinPartitions: [[(&#39;b&#39;, 2), (&#39;c&#39;, 3), (&#39;d&#39;, 3)], [(&#39;a&#39;, 1)]]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">RDD : [[&#39;a&#39;, 1], [&#39;b&#39;, 2], [&#39;c&#39;, 3], [&#39;d&#39;, 3]]\nRDD after repartitionAndSortWithinPartitions: [[(&#39;b&#39;, 2), (&#39;c&#39;, 3), (&#39;d&#39;, 3)], [(&#39;a&#39;, 1)]]\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"sparkRDD_Transformations","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4343338016982642}},"nbformat":4,"nbformat_minor":0}
